{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cadc7c0-240b-4a0e-a365-2bece0d20520",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\abiro\\OneDrive - Dewberry\\Documents\\ripple\\ripple\\conflation_metrics.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfolium\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mRiverCoverageCalculator\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "class RiverCoverageCalculator:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_path = json_path\n",
    "        self.parquet_path = parquet_path\n",
    "        self.gpkg_path = gpkg_path\n",
    "        self.json_data = None\n",
    "        self.parq = None\n",
    "        self.xs = None\n",
    "        self.river = None\n",
    "        self.matching_instances = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.json_data = pd.read_json(self.json_path)\n",
    "        self.parq = gpd.read_parquet(self.parquet_path)\n",
    "        self.xs = gpd.read_file(self.gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(self.gpkg_path, layer=\"River\")\n",
    "\n",
    "    def plot_data(self):\n",
    "        mxs = self.xs.explore(color=\"green\")\n",
    "        self.river.explore(m=mxs, color=\"blue\")\n",
    "        if self.matching_instances is not None:\n",
    "            self.matching_instances.explore(m=mxs, color=\"red\")\n",
    "\n",
    "    def find_matching_instances(self, id_value=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == id_value]\n",
    "\n",
    "    def calculate_coverage(self):\n",
    "        total_length_xs = self.xs.geometry.length.sum()\n",
    "        total_length_river = self.river.geometry.length.sum()\n",
    "        total_length_matching_instances = self.matching_instances.geometry.length.sum()\n",
    "        coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "        print(f\"Coverage Percentage: {coverage_percentage}%\")\n",
    "\n",
    "def main():\n",
    "    calculator = RiverCoverageCalculator(\n",
    "        json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "        parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "        gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    "    )\n",
    "    calculator.load_data()\n",
    "    calculator.find_matching_instances()\n",
    "    calculator.plot_data()\n",
    "    calculator.calculate_coverage()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from geopandas) (1.26.4)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.9.0-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from geopandas) (24.0)\n",
      "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from geopandas) (2.2.2)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Downloading pyproj-3.6.1-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.0.5-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.4.0->geopandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Collecting certifi (from pyogrio>=0.7.2->geopandas)\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "   ---------------------------------------- 0.0/323.6 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 81.9/323.6 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  317.4/323.6 kB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 323.6/323.6 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading pyogrio-0.9.0-cp312-cp312-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.9 MB 33.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 2.3/15.9 MB 29.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.9/15.9 MB 47.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.8/15.9 MB 50.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.9/15.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.9/15.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading pyproj-3.6.1-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 3.8/6.1 MB 79.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.1/6.1 MB 77.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.1/6.1 MB 55.7 MB/s eta 0:00:00\n",
      "Downloading shapely-2.0.5-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 46.2 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/163.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 163.0/163.0 kB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely, certifi, pyproj, pyogrio, geopandas\n",
      "Successfully installed certifi-2024.7.4 geopandas-1.0.1 pyogrio-0.9.0 pyproj-3.6.1 shapely-2.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting folium\n",
      "  Downloading folium-0.17.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Downloading branca-0.7.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jinja2>=2.9 (from folium)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from folium) (1.26.4)\n",
      "Collecting requests (from folium)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xyzservices (from folium)\n",
      "  Using cached xyzservices-2024.6.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.9->folium)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->folium)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests->folium) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests->folium) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests->folium) (2024.7.4)\n",
      "Downloading folium-0.17.0-py2.py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.4 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 102.4/108.4 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 108.4/108.4 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading branca-0.7.2-py3-none-any.whl (25 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.3/133.3 kB 7.7 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading xyzservices-2024.6.0-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 83.9/83.9 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB ? eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Installing collected packages: xyzservices, MarkupSafe, charset-normalizer, requests, jinja2, branca, folium\n",
      "Successfully installed MarkupSafe-2.1.5 branca-0.7.2 charset-normalizer-3.3.2 folium-0.17.0 jinja2-3.1.4 requests-2.32.3 xyzservices-2024.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow.parquet'. pyarrow is required for Parquet support.  \"\n        \"Use pip or conda to install pyarrow.parquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m     calculator\u001b[39m.\u001b[39mcalculate_coverage()\n\u001b[0;32m     49\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m     39\u001b[0m     calculator \u001b[39m=\u001b[39m RiverCoverageCalculator(\n\u001b[0;32m     40\u001b[0m         json_path\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mabiro\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDownloads\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBASIN FORK Trib 4-nwm_conflation (1).json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     41\u001b[0m         parquet_path\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mabiro\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDownloads\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mnwm_flows_v3 (1).parquet\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     42\u001b[0m         gpkg_path\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mabiro\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDownloads\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBASIN FORK Trib 4.gpkg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     43\u001b[0m     )\n\u001b[1;32m---> 44\u001b[0m     calculator\u001b[39m.\u001b[39;49mload_data()\n\u001b[0;32m     45\u001b[0m     calculator\u001b[39m.\u001b[39mfind_matching_instances()\n\u001b[0;32m     46\u001b[0m     calculator\u001b[39m.\u001b[39mplot_data()\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mRiverCoverageCalculator.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjson_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjson_path)\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparq \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparquet_path)\n\u001b[0;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxs \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpkg_path, layer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mXS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mriver \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpkg_path, layer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRiver\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\io\\arrow.py:739\u001b[0m, in \u001b[0;36m_read_parquet\u001b[1;34m(path, columns, storage_options, bbox, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_parquet\u001b[39m(path, columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, storage_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, bbox\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    672\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[39m    Load a Parquet object from the file path, returning a GeoDataFrame.\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[39m    ... )  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 739\u001b[0m     parquet \u001b[39m=\u001b[39m import_optional_dependency(\n\u001b[0;32m    740\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpyarrow.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m, extra\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpyarrow is required for Parquet support.\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    741\u001b[0m     )\n\u001b[0;32m    742\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pyarrow_hotfix\u001b[39;00m  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[39m# TODO(https://github.com/pandas-dev/pandas/pull/41194): see if pandas\u001b[39;00m\n\u001b[0;32m    745\u001b[0m     \u001b[39m# adds filesystem as a keyword and match that.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\_compat.py:64\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra)\u001b[0m\n\u001b[0;32m     61\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39mreturn\u001b[39;00m module\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyarrow.parquet'. pyarrow is required for Parquet support.  \"\n        \"Use pip or conda to install pyarrow.parquet."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "class RiverCoverageCalculator:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_path = json_path\n",
    "        self.parquet_path = parquet_path\n",
    "        self.gpkg_path = gpkg_path\n",
    "        self.json_data = None\n",
    "        self.parq = None\n",
    "        self.xs = None\n",
    "        self.river = None\n",
    "        self.matching_instances = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.json_data = pd.read_json(self.json_path)\n",
    "        self.parq = gpd.read_parquet(self.parquet_path)\n",
    "        self.xs = gpd.read_file(self.gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(self.gpkg_path, layer=\"River\")\n",
    "\n",
    "    def plot_data(self):\n",
    "        mxs = self.xs.explore(color=\"green\")\n",
    "        self.river.explore(m=mxs, color=\"blue\")\n",
    "        if self.matching_instances is not None:\n",
    "            self.matching_instances.explore(m=mxs, color=\"red\")\n",
    "\n",
    "    def find_matching_instances(self, id_value=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == id_value]\n",
    "\n",
    "    def calculate_coverage(self):\n",
    "        total_length_xs = self.xs.geometry.length.sum()\n",
    "        total_length_river = self.river.geometry.length.sum()\n",
    "        total_length_matching_instances = self.matching_instances.geometry.length.sum()\n",
    "        coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "        print(f\"Coverage Percentage: {coverage_percentage}%\")\n",
    "\n",
    "def main():\n",
    "    calculator = RiverCoverageCalculator(\n",
    "        json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "        parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "        gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    "    )\n",
    "    calculator.load_data()\n",
    "    calculator.find_matching_instances()\n",
    "    calculator.plot_data()\n",
    "    calculator.calculate_coverage()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pyarrow.parquet (from versions: none)\n",
      "ERROR: No matching distribution found for pyarrow.parquet\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from pyarrow) (1.26.4)\n",
      "Downloading pyarrow-17.0.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.1 MB 660.6 kB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.1/25.1 MB 656.4 kB/s eta 0:00:39\n",
      "   ---------------------------------------- 0.3/25.1 MB 2.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.7/25.1 MB 3.9 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.6/25.1 MB 7.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.5/25.1 MB 14.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.7/25.1 MB 25.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 10.8/25.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.3/25.1 MB 93.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.5/25.1 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.0/25.1 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.1 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.1 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 46.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-17.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverCoverageCalculator:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_path = json_path\n",
    "        self.parquet_path = parquet_path\n",
    "        self.gpkg_path = gpkg_path\n",
    "        self.json_data = None\n",
    "        self.parq = None\n",
    "        self.xs = None\n",
    "        self.river = None\n",
    "        self.matching_instances = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.json_data = pd.read_json(self.json_path)\n",
    "        self.parq = gpd.read_parquet(self.parquet_path)\n",
    "        self.xs = gpd.read_file(self.gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(self.gpkg_path, layer=\"River\")\n",
    "\n",
    "    def plot_data(self):\n",
    "        mxs = self.xs.explore(color=\"green\")\n",
    "        self.river.explore(m=mxs, color=\"blue\")\n",
    "        if self.matching_instances is not None:\n",
    "            self.matching_instances.explore(m=mxs, color=\"red\")\n",
    "\n",
    "    def find_matching_instances(self, id_value=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == id_value]\n",
    "\n",
    "    def calculate_coverage(self):\n",
    "        total_length_xs = self.xs.geometry.length.sum()\n",
    "        total_length_river = self.river.geometry.length.sum()\n",
    "        total_length_matching_instances = self.matching_instances.geometry.length.sum()\n",
    "        coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "        print(f\"Coverage Percentage: {coverage_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    calculator = RiverCoverageCalculator(\n",
    "        json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "        parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "        gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    "    )\n",
    "    calculator.load_data()\n",
    "    calculator.find_matching_instances()\n",
    "    calculator.plot_data()\n",
    "    calculator.calculate_coverage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The 'folium', 'matplotlib' and 'mapclassify' packages are required for 'explore()'. You can install them using 'conda install -c conda-forge folium matplotlib mapclassify' or 'pip install folium matplotlib mapclassify'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\explore.py:287\u001b[0m, in \u001b[0;36m_explore\u001b[1;34m(df, column, cmap, color, m, tiles, attr, tooltip, popup, highlight, categorical, legend, scheme, k, vmin, vmax, width, height, categories, classification_kwds, control_scale, marker_type, marker_kwds, style_kwds, highlight_kwds, missing_kwds, tooltip_kwds, popup_kwds, legend_kwds, map_kwds, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfolium\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m calculator\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m      8\u001b[0m calculator\u001b[39m.\u001b[39mfind_matching_instances()\n\u001b[1;32m----> 9\u001b[0m calculator\u001b[39m.\u001b[39;49mplot_data()\n\u001b[0;32m     10\u001b[0m calculator\u001b[39m.\u001b[39mcalculate_coverage()\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mRiverCoverageCalculator.plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     mxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxs\u001b[39m.\u001b[39;49mexplore(color\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgreen\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mriver\u001b[39m.\u001b[39mexplore(m\u001b[39m=\u001b[39mmxs, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatching_instances \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\geodataframe.py:2305\u001b[0m, in \u001b[0;36mGeoDataFrame.explore\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2303\u001b[0m \u001b[39m@doc\u001b[39m(_explore)\n\u001b[0;32m   2304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplore\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2305\u001b[0m     \u001b[39mreturn\u001b[39;00m _explore(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\explore.py:300\u001b[0m, in \u001b[0;36m_explore\u001b[1;34m(df, column, cmap, color, m, tiles, attr, tooltip, popup, highlight, categorical, legend, scheme, k, vmin, vmax, width, height, categories, classification_kwds, control_scale, marker_type, marker_kwds, style_kwds, highlight_kwds, missing_kwds, tooltip_kwds, popup_kwds, legend_kwds, map_kwds, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m cm\n\u001b[0;32m    299\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m):\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfolium\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m packages are required for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexplore()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can install them using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconda install -c conda-forge folium matplotlib mapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install folium matplotlib mapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    307\u001b[0m \u001b[39m# xyservices is an optional dependency\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: The 'folium', 'matplotlib' and 'mapclassify' packages are required for 'explore()'. You can install them using 'conda install -c conda-forge folium matplotlib mapclassify' or 'pip install folium matplotlib mapclassify'."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmapclassify\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib \n",
    "import mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlibNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading matplotlib-3.9.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl.metadata (165 kB)\n",
      "     ---------------------------------------- 0.0/165.9 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/165.9 kB ? eta -:--:--\n",
      "     ------------------- ------------------- 81.9/165.9 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  163.8/165.9 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 165.9/165.9 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.1-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.0 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.0/8.0 MB 25.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.6/8.0 MB 36.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.0/8.0 MB 50.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.0/8.0 MB 50.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 39.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.1-cp312-cp312-win_amd64.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 189.9/189.9 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.1/2.2 MB 138.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 23.2 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.0/56.0 kB ? eta 0:00:00\n",
      "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 54.1 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 kiwisolver-1.4.5 matplotlib-3.9.1 pillow-10.4.0 pyparsing-3.1.2\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The 'folium', 'matplotlib' and 'mapclassify' packages are required for 'explore()'. You can install them using 'conda install -c conda-forge folium matplotlib mapclassify' or 'pip install folium matplotlib mapclassify'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\explore.py:289\u001b[0m, in \u001b[0;36m_explore\u001b[1;34m(df, column, cmap, color, m, tiles, attr, tooltip, popup, highlight, categorical, legend, scheme, k, vmin, vmax, width, height, categories, classification_kwds, control_scale, marker_type, marker_kwds, style_kwds, highlight_kwds, missing_kwds, tooltip_kwds, popup_kwds, legend_kwds, map_kwds, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmapclassify\u001b[39;00m \u001b[39mimport\u001b[39;00m classify\n\u001b[0;32m    290\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m colors\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mapclassify'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m calculator\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m      8\u001b[0m calculator\u001b[39m.\u001b[39mfind_matching_instances()\n\u001b[1;32m----> 9\u001b[0m calculator\u001b[39m.\u001b[39;49mplot_data()\n\u001b[0;32m     10\u001b[0m calculator\u001b[39m.\u001b[39mcalculate_coverage()\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mRiverCoverageCalculator.plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     mxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxs\u001b[39m.\u001b[39;49mexplore(color\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgreen\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mriver\u001b[39m.\u001b[39mexplore(m\u001b[39m=\u001b[39mmxs, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatching_instances \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\geodataframe.py:2305\u001b[0m, in \u001b[0;36mGeoDataFrame.explore\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2303\u001b[0m \u001b[39m@doc\u001b[39m(_explore)\n\u001b[0;32m   2304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplore\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2305\u001b[0m     \u001b[39mreturn\u001b[39;00m _explore(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abiro\\AppData\\Local\\miniconda3\\envs\\myenv\\Lib\\site-packages\\geopandas\\explore.py:300\u001b[0m, in \u001b[0;36m_explore\u001b[1;34m(df, column, cmap, color, m, tiles, attr, tooltip, popup, highlight, categorical, legend, scheme, k, vmin, vmax, width, height, categories, classification_kwds, control_scale, marker_type, marker_kwds, style_kwds, highlight_kwds, missing_kwds, tooltip_kwds, popup_kwds, legend_kwds, map_kwds, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m cm\n\u001b[0;32m    299\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m):\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfolium\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m packages are required for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexplore()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can install them using \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconda install -c conda-forge folium matplotlib mapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install folium matplotlib mapclassify\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    307\u001b[0m \u001b[39m# xyservices is an optional dependency\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: The 'folium', 'matplotlib' and 'mapclassify' packages are required for 'explore()'. You can install them using 'conda install -c conda-forge folium matplotlib mapclassify' or 'pip install folium matplotlib mapclassify'."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mapclassify\n",
      "  Downloading mapclassify-2.7.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx>=2.7 (from mapclassify)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from mapclassify) (1.26.4)\n",
      "Requirement already satisfied: pandas!=1.5.0,>=1.4 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from mapclassify) (2.2.2)\n",
      "Collecting scikit-learn>=1.0 (from mapclassify)\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting scipy>=1.8 (from mapclassify)\n",
      "  Downloading scipy-1.14.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 41.0/60.8 kB 991.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas!=1.5.0,>=1.4->mapclassify) (2024.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.0->mapclassify)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0->mapclassify)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abiro\\appdata\\local\\miniconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=1.5.0,>=1.4->mapclassify) (1.16.0)\n",
      "Downloading mapclassify-2.7.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.6/58.6 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.6/1.7 MB 19.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 21.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "   ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/10.9 MB 55.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.9/10.9 MB 73.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/10.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.9/10.9 MB 59.5 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.0-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.9/44.5 MB 84.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 8.4/44.5 MB 90.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 9.8/44.5 MB 90.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 9.8/44.5 MB 90.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 14.4/44.5 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 15.4/44.5 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 19.7/44.5 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 25.4/44.5 MB 93.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 30.0/44.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.5/44.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.4/44.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.4/44.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.4/44.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.5/44.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.5/44.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.5/44.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.5/44.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 32.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 301.8/301.8 kB ? eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, networkx, joblib, scikit-learn, mapclassify\n",
      "Successfully installed joblib-1.4.2 mapclassify-2.7.0 networkx-3.3 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage Percentage: 24.61769400749904%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverCoverageCalculator:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_path = json_path\n",
    "        self.parquet_path = parquet_path\n",
    "        self.gpkg_path = gpkg_path\n",
    "        self.json_data = None\n",
    "        self.parq = None\n",
    "        self.xs = None\n",
    "        self.river = None\n",
    "        self.matching_instances = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.json_data = pd.read_json(self.json_path)\n",
    "        self.parq = gpd.read_parquet(self.parquet_path)\n",
    "        self.xs = gpd.read_file(self.gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(self.gpkg_path, layer=\"River\")\n",
    "\n",
    "    def find_matching_instances(self, id_value=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == id_value]\n",
    "\n",
    "    def calculate_coverage(self):\n",
    "        total_length_xs = self.xs.geometry.length.sum()\n",
    "        total_length_river = self.river.geometry.length.sum()\n",
    "        total_length_matching_instances = self.matching_instances.geometry.length.sum()\n",
    "        coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "        print(f\"Coverage Percentage: {coverage_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    calculator = RiverCoverageCalculator(\n",
    "        json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "        parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "        gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    "    )\n",
    "    calculator.load_data()\n",
    "    calculator.find_matching_instances()\n",
    "    calculator.calculate_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage Percentage: 24.61769400749904%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage Percentage: 24.61769400749904%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import mapclassify\n",
    "import folium\n",
    "from shapely.ops import split, snap\n",
    "\n",
    "\n",
    "# Reading the files\n",
    "json_data = pd.read_json(r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json')\n",
    "parq = gpd.read_parquet(r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet')\n",
    "xs = gpd.read_file(r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg', layer = \"XS\")\n",
    "river = gpd.read_file(r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg', layer = \"River\")\n",
    "\n",
    "mxs = xs.explore(color=\"green\")\n",
    "river.explore(m=mxs)\n",
    "\n",
    "###the json file is the road map between the gpkg and the parquet file\n",
    "#river line is in the parquet file and it has an ID of 5998592\n",
    "\n",
    "#with geopandas, compute the porportion of the river covered.\n",
    "#read in the full river from the parquet file? \n",
    "# Find all instances where 'ID' matches '5998592'\n",
    "matching_instances = parq[parq['ID'] == 5998592]\n",
    "##^ that's the river we're looking for\n",
    "\n",
    "###want to plot the parquet file on the river too\n",
    "mxs = xs.explore(color=\"green\")\n",
    "mxs = river.explore(m=mxs, color = \"blue\")\n",
    "matching_instances.explore(m=mxs, color = \"red\")\n",
    "\n",
    "\n",
    "\n",
    "#####PART 1: Calculate the coverage of the river by the cross sections\n",
    "###then calculate the coverage of 5998592 from the cross sections according\n",
    "#the whole of the parquet river\n",
    "#calculate the total area of the cross sections\n",
    "total_length_xs = xs.geometry.length.sum() #incorrect, overestimating the way it's calculating length\n",
    "total_length_river = river.geometry.length.sum()\n",
    "\n",
    "\n",
    "#calculate the intersection area between the cross sections and the river\n",
    "total_length_matching_instances = matching_instances.geometry.length.sum()\n",
    "\n",
    "# Calculate the coverage percentage\n",
    "coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "\n",
    "print(f\"Coverage Percentage: {coverage_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString, MultiLineString\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_classify_line(line):\n",
    "    # Calculate the distances for splitting\n",
    "    total_length = line.length\n",
    "    one_third_distance = total_length / 3\n",
    "    two_thirds_distance = 2 * total_length / 3\n",
    "\n",
    "    # Create the segments\n",
    "    segments = [\n",
    "        LineString([line.interpolate(0), line.interpolate(one_third_distance)]),\n",
    "        LineString([line.interpolate(one_third_distance), line.interpolate(two_thirds_distance)]),\n",
    "        LineString([line.interpolate(two_thirds_distance), line.interpolate(total_length)])\n",
    "    ]\n",
    "    \n",
    "    # Classify each segment\n",
    "    classifications = ['upstream', 'middle', 'downstream']\n",
    "    \n",
    "    # Create a list to hold the new rows\n",
    "    new_rows = []\n",
    "    for segment, classification in zip(segments, classifications):\n",
    "        new_row = {'geometry': segment, 'classification': classification}\n",
    "        new_rows.append(new_row)\n",
    "    \n",
    "    # Create a GeoDataFrame from the new rows\n",
    "    return gpd.GeoDataFrame(new_rows, columns=['geometry', 'classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                geometry classification\n",
      "0  LINESTRING (0 0, 1 1)       upstream\n",
      "1  LINESTRING (1 1, 2 2)         middle\n",
      "2  LINESTRING (2 2, 3 3)     downstream\n"
     ]
    }
   ],
   "source": [
    "line = LineString([(0, 0), (1, 1), (2, 2), (3, 3)])\n",
    "split_gdf = split_and_classify_line(line)\n",
    "print(split_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: downstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-089b88aba670>:7: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = river.geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'river' is the full river GeoDataFrame and 'matching_instances' contains the overlapping sections\n",
    "\n",
    "# Calculate the centroid of the overlapping part\n",
    "centroid = matching_instances.geometry.centroid\n",
    "\n",
    "# Assuming the river is a single LineString for simplicity. If it's MultiLineString, additional handling is needed\n",
    "river_line = river.geometry.unary_union\n",
    "\n",
    "# Calculate the distance of the centroid from the start of the river\n",
    "distance_from_start = river_line.project(centroid.iloc[0])\n",
    "\n",
    "# Calculate the total length of the river\n",
    "total_length_river = river_line.length\n",
    "\n",
    "# Classify the part of the river\n",
    "if distance_from_start < total_length_river / 3:\n",
    "    classification = \"upstream\"\n",
    "elif distance_from_start < 2 * total_length_river / 3:\n",
    "    classification = \"middle\"\n",
    "else:\n",
    "    classification = \"downstream\"\n",
    "\n",
    "print(f\"The overlapping part of the river is classified as: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_a5e4e000787537bec6bc523187b1ad70 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    \n",
       "                    &lt;style&gt;\n",
       "                        .foliumtooltip {\n",
       "                            \n",
       "                        }\n",
       "                       .foliumtooltip table{\n",
       "                            margin: auto;\n",
       "                        }\n",
       "                        .foliumtooltip tr{\n",
       "                            text-align: left;\n",
       "                        }\n",
       "                        .foliumtooltip th{\n",
       "                            padding: 2px; padding-right: 8px;\n",
       "                        }\n",
       "                    &lt;/style&gt;\n",
       "            \n",
       "    \n",
       "    &lt;script src=&quot;https://code.jquery.com/ui/1.12.1/jquery-ui.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script&gt;$( function() {\n",
       "        $( &quot;.maplegend&quot; ).draggable({\n",
       "            start: function (event, ui) {\n",
       "                $(this).css({\n",
       "                    right: &quot;auto&quot;,\n",
       "                    top: &quot;auto&quot;,\n",
       "                    bottom: &quot;auto&quot;\n",
       "                });\n",
       "            }\n",
       "        });\n",
       "    });\n",
       "    &lt;/script&gt;\n",
       "    &lt;style type=&#x27;text/css&#x27;&gt;\n",
       "      .maplegend {\n",
       "        position: absolute;\n",
       "        z-index:9999;\n",
       "        background-color: rgba(255, 255, 255, .8);\n",
       "        border-radius: 5px;\n",
       "        box-shadow: 0 0 15px rgba(0,0,0,0.2);\n",
       "        padding: 10px;\n",
       "        font: 12px/14px Arial, Helvetica, sans-serif;\n",
       "        right: 10px;\n",
       "        bottom: 20px;\n",
       "      }\n",
       "      .maplegend .legend-title {\n",
       "        text-align: left;\n",
       "        margin-bottom: 5px;\n",
       "        font-weight: bold;\n",
       "        }\n",
       "      .maplegend .legend-scale ul {\n",
       "        margin: 0;\n",
       "        margin-bottom: 0px;\n",
       "        padding: 0;\n",
       "        float: left;\n",
       "        list-style: none;\n",
       "        }\n",
       "      .maplegend .legend-scale ul li {\n",
       "        list-style: none;\n",
       "        margin-left: 0;\n",
       "        line-height: 16px;\n",
       "        margin-bottom: 2px;\n",
       "        }\n",
       "      .maplegend ul.legend-labels li span {\n",
       "        display: block;\n",
       "        float: left;\n",
       "        height: 14px;\n",
       "        width: 14px;\n",
       "        margin-right: 5px;\n",
       "        margin-left: 0;\n",
       "        border: 0px solid #ccc;\n",
       "        }\n",
       "      .maplegend .legend-source {\n",
       "        color: #777;\n",
       "        clear: both;\n",
       "        }\n",
       "      .maplegend a {\n",
       "        color: #777;\n",
       "        }\n",
       "    &lt;/style&gt;\n",
       "    \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "    &lt;div id=&#x27;maplegend classification&#x27; class=&#x27;maplegend&#x27;&gt;\n",
       "        &lt;div class=&#x27;legend-title&#x27;&gt;classification&lt;/div&gt;\n",
       "        &lt;div class=&#x27;legend-scale&#x27;&gt;\n",
       "            &lt;ul class=&#x27;legend-labels&#x27;&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#440154&#x27;&gt;&lt;/span&gt;downstream&lt;/li&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#21918c&#x27;&gt;&lt;/span&gt;middle&lt;/li&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#fde725&#x27;&gt;&lt;/span&gt;upstream&lt;/li&gt;\n",
       "            &lt;/ul&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_a5e4e000787537bec6bc523187b1ad70&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_a5e4e000787537bec6bc523187b1ad70 = L.map(\n",
       "                &quot;map_a5e4e000787537bec6bc523187b1ad70&quot;,\n",
       "                {\n",
       "                    center: [1.5, 1.5],\n",
       "                    crs: L.CRS.Simple,\n",
       "                    zoom: 10,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "            L.control.scale().addTo(map_a5e4e000787537bec6bc523187b1ad70);\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            map_a5e4e000787537bec6bc523187b1ad70.fitBounds(\n",
       "                [[0.0, 0.0], [3.0, 3.0]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "        function geo_json_41d5c5ac5645b0a4b60c740ae9399225_styler(feature) {\n",
       "            switch(feature.id) {\n",
       "                case &quot;0&quot;: \n",
       "                    return {&quot;color&quot;: &quot;#fde725&quot;, &quot;fillColor&quot;: &quot;#fde725&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "                case &quot;1&quot;: \n",
       "                    return {&quot;color&quot;: &quot;#21918c&quot;, &quot;fillColor&quot;: &quot;#21918c&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "                default:\n",
       "                    return {&quot;color&quot;: &quot;#440154&quot;, &quot;fillColor&quot;: &quot;#440154&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_41d5c5ac5645b0a4b60c740ae9399225_highlighter(feature) {\n",
       "            switch(feature.id) {\n",
       "                default:\n",
       "                    return {&quot;fillOpacity&quot;: 0.75};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_41d5c5ac5645b0a4b60c740ae9399225_pointToLayer(feature, latlng) {\n",
       "            var opts = {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 2, &quot;stroke&quot;: true, &quot;weight&quot;: 3};\n",
       "            \n",
       "            let style = geo_json_41d5c5ac5645b0a4b60c740ae9399225_styler(feature)\n",
       "            Object.assign(opts, style)\n",
       "            \n",
       "            return new L.CircleMarker(latlng, opts)\n",
       "        }\n",
       "\n",
       "        function geo_json_41d5c5ac5645b0a4b60c740ae9399225_onEachFeature(feature, layer) {\n",
       "            layer.on({\n",
       "                mouseout: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                            geo_json_41d5c5ac5645b0a4b60c740ae9399225.resetStyle(e.target);\n",
       "                    }\n",
       "                },\n",
       "                mouseover: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                        const highlightStyle = geo_json_41d5c5ac5645b0a4b60c740ae9399225_highlighter(e.target.feature)\n",
       "                        e.target.setStyle(highlightStyle);\n",
       "                    }\n",
       "                },\n",
       "            });\n",
       "        };\n",
       "        var geo_json_41d5c5ac5645b0a4b60c740ae9399225 = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_41d5c5ac5645b0a4b60c740ae9399225_onEachFeature,\n",
       "            \n",
       "                style: geo_json_41d5c5ac5645b0a4b60c740ae9399225_styler,\n",
       "                pointToLayer: geo_json_41d5c5ac5645b0a4b60c740ae9399225_pointToLayer,\n",
       "        });\n",
       "\n",
       "        function geo_json_41d5c5ac5645b0a4b60c740ae9399225_add (data) {\n",
       "            geo_json_41d5c5ac5645b0a4b60c740ae9399225\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_41d5c5ac5645b0a4b60c740ae9399225_add({&quot;bbox&quot;: [0.0, 0.0, 3.0, 3.0], &quot;features&quot;: [{&quot;bbox&quot;: [0.0, 0.0, 1.0, 1.0], &quot;geometry&quot;: {&quot;coordinates&quot;: [[0.0, 0.0], [1.0, 1.0]], &quot;type&quot;: &quot;LineString&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;classification&quot;: &quot;upstream&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [1.0, 1.0, 2.0, 2.0], &quot;geometry&quot;: {&quot;coordinates&quot;: [[1.0, 1.0], [2.0, 2.0]], &quot;type&quot;: &quot;LineString&quot;}, &quot;id&quot;: &quot;1&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#21918c&quot;, &quot;classification&quot;: &quot;middle&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [2.0, 2.0, 3.0, 3.0], &quot;geometry&quot;: {&quot;coordinates&quot;: [[2.0, 2.0], [3.0, 3.0]], &quot;type&quot;: &quot;LineString&quot;}, &quot;id&quot;: &quot;2&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;classification&quot;: &quot;downstream&quot;}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "\n",
       "        \n",
       "    \n",
       "    geo_json_41d5c5ac5645b0a4b60c740ae9399225.bindTooltip(\n",
       "    function(layer){\n",
       "    let div = L.DomUtil.create(&#x27;div&#x27;);\n",
       "    \n",
       "    let handleObject = feature=&gt;typeof(feature)==&#x27;object&#x27; ? JSON.stringify(feature) : feature;\n",
       "    let fields = [&quot;classification&quot;];\n",
       "    let aliases = [&quot;classification&quot;];\n",
       "    let table = &#x27;&lt;table&gt;&#x27; +\n",
       "        String(\n",
       "        fields.map(\n",
       "        (v,i)=&gt;\n",
       "        `&lt;tr&gt;\n",
       "            &lt;th&gt;${aliases[i]}&lt;/th&gt;\n",
       "            \n",
       "            &lt;td&gt;${handleObject(layer.feature.properties[v])}&lt;/td&gt;\n",
       "        &lt;/tr&gt;`).join(&#x27;&#x27;))\n",
       "    +&#x27;&lt;/table&gt;&#x27;;\n",
       "    div.innerHTML=table;\n",
       "    \n",
       "    return div\n",
       "    }\n",
       "    ,{&quot;className&quot;: &quot;foliumtooltip&quot;, &quot;sticky&quot;: true});\n",
       "                     \n",
       "    \n",
       "            geo_json_41d5c5ac5645b0a4b60c740ae9399225.addTo(map_a5e4e000787537bec6bc523187b1ad70);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x227b79795b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_gdf.explore(column='classification', cmap='viridis', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                geometry classification\n",
      "0  LINESTRING (0 0, 1 1)     downstream\n",
      "1  LINESTRING (1 1, 2 2)         middle\n",
      "2  LINESTRING (2 2, 3 3)       upstream\n"
     ]
    }
   ],
   "source": [
    "def split_and_classify_line(line):\n",
    "    # Calculate the distances for splitting\n",
    "    total_length = line.length\n",
    "    one_third_distance = total_length / 3\n",
    "    two_thirds_distance = 2 * total_length / 3\n",
    "\n",
    "    # Create the segments\n",
    "    segments = [\n",
    "        LineString([line.interpolate(0), line.interpolate(one_third_distance)]),\n",
    "        LineString([line.interpolate(one_third_distance), line.interpolate(two_thirds_distance)]),\n",
    "        LineString([line.interpolate(two_thirds_distance), line.interpolate(total_length)])\n",
    "    ]\n",
    "    \n",
    "    # Classify each segment with swapped classifications\n",
    "    classifications = ['downstream', 'middle', 'upstream']\n",
    "    \n",
    "    # Create a list to hold the new rows\n",
    "    new_rows = []\n",
    "    for segment, classification in zip(segments, classifications):\n",
    "        new_row = {'geometry': segment, 'classification': classification}\n",
    "        new_rows.append(new_row)\n",
    "    \n",
    "    # Create a GeoDataFrame from the new rows\n",
    "    return gpd.GeoDataFrame(new_rows, columns=['geometry', 'classification'])\n",
    "\n",
    "# Example usage\n",
    "line = LineString([(0, 0), (1, 1), (2, 2), (3, 3)])\n",
    "split_gdf = split_and_classify_line(line)\n",
    "print(split_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: downstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-a0793e240051>:4: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = river.geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "centroid = matching_instances.geometry.centroid\n",
    "\n",
    "# Assuming the river is a single LineString for simplicity. If it's MultiLineString, additional handling is needed\n",
    "river_line = river.geometry.unary_union\n",
    "\n",
    "# Calculate the distance of the centroid from the start of the river\n",
    "distance_from_start = river_line.project(centroid.iloc[0])\n",
    "\n",
    "# Calculate the total length of the river\n",
    "total_length_river = river_line.length\n",
    "\n",
    "# Classify the part of the river\n",
    "if distance_from_start < total_length_river / 3:\n",
    "    classification = \"upstream\"\n",
    "elif distance_from_start < 2 * total_length_river / 3:\n",
    "    classification = \"middle\"\n",
    "else:\n",
    "    classification = \"downstream\"\n",
    "\n",
    "print(f\"The overlapping part of the river is classified as: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: upstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-b64c6c2667f6>:5: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = river.geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "# Calculate the centroid of the overlapping part\n",
    "centroid = matching_instances.geometry.centroid\n",
    "\n",
    "# Assuming the river is a single LineString for simplicity. If it's MultiLineString, additional handling is needed\n",
    "river_line = river.geometry.unary_union\n",
    "\n",
    "# Calculate the distance of the centroid from the start of the river\n",
    "distance_from_start = river_line.project(centroid.iloc[0])\n",
    "\n",
    "# Calculate the total length of the river\n",
    "total_length_river = river_line.length\n",
    "\n",
    "# Classify the part of the river with swapped classifications\n",
    "if distance_from_start < total_length_river / 3:\n",
    "    classification = \"downstream\"  # Swapped\n",
    "elif distance_from_start < 2 * total_length_river / 3:\n",
    "    classification = \"middle\"\n",
    "else:\n",
    "    classification = \"upstream\"  # Swapped\n",
    "\n",
    "print(f\"The overlapping part of the river is classified as: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_05ed3420ffd9594fc4de7d6d7131c709 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    \n",
       "                    &lt;style&gt;\n",
       "                        .foliumtooltip {\n",
       "                            \n",
       "                        }\n",
       "                       .foliumtooltip table{\n",
       "                            margin: auto;\n",
       "                        }\n",
       "                        .foliumtooltip tr{\n",
       "                            text-align: left;\n",
       "                        }\n",
       "                        .foliumtooltip th{\n",
       "                            padding: 2px; padding-right: 8px;\n",
       "                        }\n",
       "                    &lt;/style&gt;\n",
       "            \n",
       "    \n",
       "    &lt;script src=&quot;https://code.jquery.com/ui/1.12.1/jquery-ui.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script&gt;$( function() {\n",
       "        $( &quot;.maplegend&quot; ).draggable({\n",
       "            start: function (event, ui) {\n",
       "                $(this).css({\n",
       "                    right: &quot;auto&quot;,\n",
       "                    top: &quot;auto&quot;,\n",
       "                    bottom: &quot;auto&quot;\n",
       "                });\n",
       "            }\n",
       "        });\n",
       "    });\n",
       "    &lt;/script&gt;\n",
       "    &lt;style type=&#x27;text/css&#x27;&gt;\n",
       "      .maplegend {\n",
       "        position: absolute;\n",
       "        z-index:9999;\n",
       "        background-color: rgba(255, 255, 255, .8);\n",
       "        border-radius: 5px;\n",
       "        box-shadow: 0 0 15px rgba(0,0,0,0.2);\n",
       "        padding: 10px;\n",
       "        font: 12px/14px Arial, Helvetica, sans-serif;\n",
       "        right: 10px;\n",
       "        bottom: 20px;\n",
       "      }\n",
       "      .maplegend .legend-title {\n",
       "        text-align: left;\n",
       "        margin-bottom: 5px;\n",
       "        font-weight: bold;\n",
       "        }\n",
       "      .maplegend .legend-scale ul {\n",
       "        margin: 0;\n",
       "        margin-bottom: 0px;\n",
       "        padding: 0;\n",
       "        float: left;\n",
       "        list-style: none;\n",
       "        }\n",
       "      .maplegend .legend-scale ul li {\n",
       "        list-style: none;\n",
       "        margin-left: 0;\n",
       "        line-height: 16px;\n",
       "        margin-bottom: 2px;\n",
       "        }\n",
       "      .maplegend ul.legend-labels li span {\n",
       "        display: block;\n",
       "        float: left;\n",
       "        height: 14px;\n",
       "        width: 14px;\n",
       "        margin-right: 5px;\n",
       "        margin-left: 0;\n",
       "        border: 0px solid #ccc;\n",
       "        }\n",
       "      .maplegend .legend-source {\n",
       "        color: #777;\n",
       "        clear: both;\n",
       "        }\n",
       "      .maplegend a {\n",
       "        color: #777;\n",
       "        }\n",
       "    &lt;/style&gt;\n",
       "    \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "    &lt;div id=&#x27;maplegend classification&#x27; class=&#x27;maplegend&#x27;&gt;\n",
       "        &lt;div class=&#x27;legend-title&#x27;&gt;classification&lt;/div&gt;\n",
       "        &lt;div class=&#x27;legend-scale&#x27;&gt;\n",
       "            &lt;ul class=&#x27;legend-labels&#x27;&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#440154&#x27;&gt;&lt;/span&gt;downstream&lt;/li&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#21918c&#x27;&gt;&lt;/span&gt;middle&lt;/li&gt;\n",
       "                &lt;li&gt;&lt;span style=&#x27;background:#fde725&#x27;&gt;&lt;/span&gt;upstream&lt;/li&gt;\n",
       "            &lt;/ul&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_05ed3420ffd9594fc4de7d6d7131c709&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_05ed3420ffd9594fc4de7d6d7131c709 = L.map(\n",
       "                &quot;map_05ed3420ffd9594fc4de7d6d7131c709&quot;,\n",
       "                {\n",
       "                    center: [1.5, 1.5],\n",
       "                    crs: L.CRS.Simple,\n",
       "                    zoom: 10,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "            L.control.scale().addTo(map_05ed3420ffd9594fc4de7d6d7131c709);\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            map_05ed3420ffd9594fc4de7d6d7131c709.fitBounds(\n",
       "                [[0.0, 0.0], [3.0, 3.0]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "        function geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_styler(feature) {\n",
       "            switch(feature.id) {\n",
       "                case &quot;0&quot;: \n",
       "                    return {&quot;color&quot;: &quot;#440154&quot;, &quot;fillColor&quot;: &quot;#440154&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "                case &quot;1&quot;: \n",
       "                    return {&quot;color&quot;: &quot;#21918c&quot;, &quot;fillColor&quot;: &quot;#21918c&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "                default:\n",
       "                    return {&quot;color&quot;: &quot;#fde725&quot;, &quot;fillColor&quot;: &quot;#fde725&quot;, &quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_highlighter(feature) {\n",
       "            switch(feature.id) {\n",
       "                default:\n",
       "                    return {&quot;fillOpacity&quot;: 0.75};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_pointToLayer(feature, latlng) {\n",
       "            var opts = {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 2, &quot;stroke&quot;: true, &quot;weight&quot;: 3};\n",
       "            \n",
       "            let style = geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_styler(feature)\n",
       "            Object.assign(opts, style)\n",
       "            \n",
       "            return new L.CircleMarker(latlng, opts)\n",
       "        }\n",
       "\n",
       "        function geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_onEachFeature(feature, layer) {\n",
       "            layer.on({\n",
       "                mouseout: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                            geo_json_971c0af53d5fbd5e4e4ad7f72ec71643.resetStyle(e.target);\n",
       "                    }\n",
       "                },\n",
       "                mouseover: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                        const highlightStyle = geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_highlighter(e.target.feature)\n",
       "                        e.target.setStyle(highlightStyle);\n",
       "                    }\n",
       "                },\n",
       "            });\n",
       "        };\n",
       "        var geo_json_971c0af53d5fbd5e4e4ad7f72ec71643 = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_onEachFeature,\n",
       "            \n",
       "                style: geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_styler,\n",
       "                pointToLayer: geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_pointToLayer,\n",
       "        });\n",
       "\n",
       "        function geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_add (data) {\n",
       "            geo_json_971c0af53d5fbd5e4e4ad7f72ec71643\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_971c0af53d5fbd5e4e4ad7f72ec71643_add({&quot;bbox&quot;: [0.0, 0.0, 3.0, 3.0], &quot;features&quot;: [{&quot;bbox&quot;: [0.0, 0.0, 1.0, 1.0], &quot;geometry&quot;: {&quot;coordinates&quot;: [[0.0, 0.0], [1.0, 1.0]], &quot;type&quot;: &quot;LineString&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#440154&quot;, &quot;classification&quot;: &quot;downstream&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [1.0, 1.0, 2.0, 2.0], &quot;geometry&quot;: {&quot;coordinates&quot;: [[1.0, 1.0], [2.0, 2.0]], &quot;type&quot;: &quot;LineString&quot;}, &quot;id&quot;: &quot;1&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#21918c&quot;, &quot;classification&quot;: &quot;middle&quot;}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [2.0, 2.0, 3.0, 3.0], &quot;geometry&quot;: {&quot;coordinates&quot;: [[2.0, 2.0], [3.0, 3.0]], &quot;type&quot;: &quot;LineString&quot;}, &quot;id&quot;: &quot;2&quot;, &quot;properties&quot;: {&quot;__folium_color&quot;: &quot;#fde725&quot;, &quot;classification&quot;: &quot;upstream&quot;}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "\n",
       "        \n",
       "    \n",
       "    geo_json_971c0af53d5fbd5e4e4ad7f72ec71643.bindTooltip(\n",
       "    function(layer){\n",
       "    let div = L.DomUtil.create(&#x27;div&#x27;);\n",
       "    \n",
       "    let handleObject = feature=&gt;typeof(feature)==&#x27;object&#x27; ? JSON.stringify(feature) : feature;\n",
       "    let fields = [&quot;classification&quot;];\n",
       "    let aliases = [&quot;classification&quot;];\n",
       "    let table = &#x27;&lt;table&gt;&#x27; +\n",
       "        String(\n",
       "        fields.map(\n",
       "        (v,i)=&gt;\n",
       "        `&lt;tr&gt;\n",
       "            &lt;th&gt;${aliases[i]}&lt;/th&gt;\n",
       "            \n",
       "            &lt;td&gt;${handleObject(layer.feature.properties[v])}&lt;/td&gt;\n",
       "        &lt;/tr&gt;`).join(&#x27;&#x27;))\n",
       "    +&#x27;&lt;/table&gt;&#x27;;\n",
       "    div.innerHTML=table;\n",
       "    \n",
       "    return div\n",
       "    }\n",
       "    ,{&quot;className&quot;: &quot;foliumtooltip&quot;, &quot;sticky&quot;: true});\n",
       "                     \n",
       "    \n",
       "            geo_json_971c0af53d5fbd5e4e4ad7f72ec71643.addTo(map_05ed3420ffd9594fc4de7d6d7131c709);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x227e1347d10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_gdf.explore(column='classification', cmap='viridis', legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflation Results\n",
      "Quantitative Coverage: 24.6%\n",
      "Section of River Covered: upstream\n"
     ]
    }
   ],
   "source": [
    "###then have nice pretty Conflation Results Output:\n",
    "print(\"Conflation Results\")\n",
    "print(f\"Quantitative Coverage: {round(coverage_percentage, 1)}%\")\n",
    "print(f\"Section of River Covered: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                geometry classification\n",
      "0  LINESTRING (0 0, 1 1)     downstream\n",
      "1  LINESTRING (1 1, 2 2)         middle\n",
      "2  LINESTRING (2 2, 3 3)       upstream\n",
      "The overlapping part of the river is classified as: upstream\n",
      "Conflation Results\n",
      "Quantitative Coverage: 24.6%\n",
      "Section of River Covered: upstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-77c8ca1d787f>:67: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = river.geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "# Reading the files\n",
    "json_data = pd.read_json(r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json')\n",
    "parq = gpd.read_parquet(r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet')\n",
    "xs = gpd.read_file(r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg', layer = \"XS\")\n",
    "river = gpd.read_file(r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg', layer = \"River\")\n",
    "\n",
    "mxs = xs.explore(color=\"green\")\n",
    "river.explore(m=mxs)\n",
    "\n",
    "###the json file is the road map between the gpkg and the parquet file\n",
    "#river line is in the parquet file and it has an ID of 5998592\n",
    "\n",
    "#with geopandas, compute the porportion of the river covered.\n",
    "#read in the full river from the parquet file? \n",
    "# Find all instances where 'ID' matches '5998592'\n",
    "matching_instances = parq[parq['ID'] == 5998592]\n",
    "##^ that's the river we're looking for\n",
    "\n",
    "###want to plot the parquet file on the river too\n",
    "mxs = xs.explore(color=\"green\")\n",
    "mxs = river.explore(m=mxs, color = \"blue\")\n",
    "matching_instances.explore(m=mxs, color = \"red\")\n",
    "\n",
    "\n",
    "\n",
    "#####PART 1: Calculate the coverage of the river by the cross sections\n",
    "###then calculate the coverage of 5998592 from the cross sections according\n",
    "#the whole of the parquet river\n",
    "#calculate the total area of the cross sections\n",
    "def split_and_classify_line(line):\n",
    "    # Calculate the distances for splitting\n",
    "    total_length = line.length\n",
    "    one_third_distance = total_length / 3\n",
    "    two_thirds_distance = 2 * total_length / 3\n",
    "\n",
    "    # Create the segments\n",
    "    segments = [\n",
    "        LineString([line.interpolate(0), line.interpolate(one_third_distance)]),\n",
    "        LineString([line.interpolate(one_third_distance), line.interpolate(two_thirds_distance)]),\n",
    "        LineString([line.interpolate(two_thirds_distance), line.interpolate(total_length)])\n",
    "    ]\n",
    "    \n",
    "    # Classify each segment with swapped classifications\n",
    "    classifications = ['downstream', 'middle', 'upstream']\n",
    "    \n",
    "    # Create a list to hold the new rows\n",
    "    new_rows = []\n",
    "    for segment, classification in zip(segments, classifications):\n",
    "        new_row = {'geometry': segment, 'classification': classification}\n",
    "        new_rows.append(new_row)\n",
    "    \n",
    "    # Create a GeoDataFrame from the new rows\n",
    "    return gpd.GeoDataFrame(new_rows, columns=['geometry', 'classification'])\n",
    "\n",
    "# Example usage\n",
    "line = LineString([(0, 0), (1, 1), (2, 2), (3, 3)])\n",
    "split_gdf = split_and_classify_line(line)\n",
    "print(split_gdf)\n",
    "\n",
    "\n",
    "# Assuming 'river' is the full river GeoDataFrame and 'matching_instances' contains the overlapping sections\n",
    "\n",
    "# Calculate the centroid of the overlapping part\n",
    "centroid = matching_instances.geometry.centroid\n",
    "\n",
    "# Assuming the river is a single LineString for simplicity. If it's MultiLineString, additional handling is needed\n",
    "river_line = river.geometry.unary_union\n",
    "\n",
    "# Calculate the distance of the centroid from the start of the river\n",
    "distance_from_start = river_line.project(centroid.iloc[0])\n",
    "\n",
    "# Calculate the total length of the river\n",
    "total_length_river = river_line.length\n",
    "\n",
    "# Classify the part of the river with swapped classifications\n",
    "if distance_from_start < total_length_river / 3:\n",
    "    classification = \"downstream\"  # Swapped\n",
    "elif distance_from_start < 2 * total_length_river / 3:\n",
    "    classification = \"middle\"\n",
    "else:\n",
    "    classification = \"upstream\"  # Swapped\n",
    "\n",
    "print(f\"The overlapping part of the river is classified as: {classification}\")\n",
    "\n",
    "split_gdf.explore(column='classification', cmap='viridis', legend=True)\n",
    "\n",
    "######PART 3: Conflation Results\n",
    "###then have nice pretty Conflation Results Output:\n",
    "print(\"Conflation Results\")\n",
    "print(f\"Quantitative Coverage: {round(coverage_percentage, 1)}%\")\n",
    "print(f\"Section of River Covered: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: upstream\n",
      "Conflation Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-f48c1bbb4bb1>:45: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = self.river.geometry.unary_union\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type NoneType doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m analyzer\u001b[39m.\u001b[39mfind_matching_instances()\n\u001b[0;32m     71\u001b[0m analyzer\u001b[39m.\u001b[39mclassify_river_part()\n\u001b[1;32m---> 72\u001b[0m analyzer\u001b[39m.\u001b[39;49mdisplay_results()\n",
      "Cell \u001b[1;32mIn[31], line 60\u001b[0m, in \u001b[0;36mRiverAnalyzer.display_results\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39m# Placeholder for coverage calculation\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConflation Results\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuantitative Coverage: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoverage_percentage,\u001b[39m \u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSection of River Covered: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: type NoneType doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "class RiverAnalyzer:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_data = pd.read_json(json_path)\n",
    "        self.parq = gpd.read_parquet(parquet_path)\n",
    "        self.xs = gpd.read_file(gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(gpkg_path, layer=\"River\")\n",
    "        self.mxs = None\n",
    "        self.matching_instances = None\n",
    "        self.classification = None\n",
    "        self.coverage_percentage = None  # Placeholder for coverage calculation\n",
    "\n",
    "    def plot_initial_data(self):\n",
    "        self.mxs = self.xs.explore(color=\"green\")\n",
    "        self.river.explore(m=self.mxs)\n",
    "\n",
    "    def find_matching_instances(self, river_id=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == river_id]\n",
    "        self.mxs = self.xs.explore(color=\"green\")\n",
    "        self.mxs = self.river.explore(m=self.mxs, color=\"blue\")\n",
    "        self.matching_instances.explore(m=self.mxs, color=\"red\")\n",
    "\n",
    "    @staticmethod\n",
    "    def split_and_classify_line(line):\n",
    "        total_length = line.length\n",
    "        one_third_distance = total_length / 3\n",
    "        two_thirds_distance = 2 * total_length / 3\n",
    "\n",
    "        segments = [\n",
    "            LineString([line.interpolate(0), line.interpolate(one_third_distance)]),\n",
    "            LineString([line.interpolate(one_third_distance), line.interpolate(two_thirds_distance)]),\n",
    "            LineString([line.interpolate(two_thirds_distance), line.interpolate(total_length)])\n",
    "        ]\n",
    "\n",
    "        classifications = ['downstream', 'middle', 'upstream']\n",
    "        new_rows = [{'geometry': segment, 'classification': classification} for segment, classification in zip(segments, classifications)]\n",
    "\n",
    "        return gpd.GeoDataFrame(new_rows, columns=['geometry', 'classification'])\n",
    "\n",
    "    def classify_river_part(self):\n",
    "        centroid = self.matching_instances.geometry.centroid\n",
    "        river_line = self.river.geometry.unary_union\n",
    "        distance_from_start = river_line.project(centroid.iloc[0])\n",
    "        total_length_river = river_line.length\n",
    "\n",
    "        if distance_from_start < total_length_river / 3:\n",
    "            self.classification = \"downstream\"\n",
    "        elif distance_from_start < 2 * total_length_river / 3:\n",
    "            self.classification = \"middle\"\n",
    "        else:\n",
    "            self.classification = \"upstream\"\n",
    "\n",
    "    def display_results(self):\n",
    "        print(f\"The overlapping part of the river is classified as: {self.classification}\")\n",
    "        # Placeholder for coverage calculation\n",
    "        print(\"Conflation Results\")\n",
    "        print(f\"Quantitative Coverage: {round(self.coverage_percentage, 1)}%\")\n",
    "        print(f\"Section of River Covered: {self.classification}\")\n",
    "\n",
    "# Example usage\n",
    "analyzer = RiverAnalyzer(\n",
    "    json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "    parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "    gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    ")\n",
    "analyzer.plot_initial_data()\n",
    "analyzer.find_matching_instances()\n",
    "analyzer.classify_river_part()\n",
    "analyzer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverAnalyzer:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_data = pd.read_json(json_path)\n",
    "        self.parq = gpd.read_parquet(parquet_path)\n",
    "        self.xs = gpd.read_file(gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(gpkg_path, layer=\"River\")\n",
    "        self.matching_instances = None\n",
    "        self.classification = None\n",
    "        self.coverage_percentage = None  # Placeholder for coverage calculation\n",
    "\n",
    "    def find_matching_instances(self, river_id=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == river_id]\n",
    "\n",
    "    @staticmethod\n",
    "    def split_and_classify_line(line):\n",
    "        total_length = line.length\n",
    "        one_third_distance = total_length / 3\n",
    "        two_thirds_distance = 2 * total_length / 3\n",
    "\n",
    "        segments = [\n",
    "            LineString([line.interpolate(0), line.interpolate(one_third_distance)]),\n",
    "            LineString([line.interpolate(one_third_distance), line.interpolate(two_thirds_distance)]),\n",
    "            LineString([line.interpolate(two_thirds_distance), line.interpolate(total_length)])\n",
    "        ]\n",
    "\n",
    "        classifications = ['downstream', 'middle', 'upstream']\n",
    "        new_rows = [{'geometry': segment, 'classification': classification} for segment, classification in zip(segments, classifications)]\n",
    "\n",
    "        return gpd.GeoDataFrame(new_rows, columns=['geometry', 'classification'])\n",
    "\n",
    "    def classify_river_part(self):\n",
    "        centroid = self.matching_instances.geometry.centroid\n",
    "        river_line = self.river.geometry.unary_union\n",
    "        distance_from_start = river_line.project(centroid.iloc[0])\n",
    "        total_length_river = river_line.length\n",
    "\n",
    "        if distance_from_start < total_length_river / 3:\n",
    "            self.classification = \"downstream\"\n",
    "        elif distance_from_start < 2 * total_length_river / 3:\n",
    "            self.classification = \"middle\"\n",
    "        else:\n",
    "            self.classification = \"upstream\"\n",
    "\n",
    "    def display_results(self):\n",
    "        print(f\"The overlapping part of the river is classified as: {self.classification}\")\n",
    "        # Placeholder for coverage calculation\n",
    "        print(\"Conflation Results\")\n",
    "        print(f\"Quantitative Coverage: {round(self.coverage_percentage, 1)}%\")\n",
    "        print(f\"Section of River Covered: {self.classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = RiverAnalyzer(\n",
    "    json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "    parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "    gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.find_matching_instances()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-3764f5469f46>:33: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = self.river.geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "analyzer.classify_river_part()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: upstream\n",
      "Conflation Results\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type NoneType doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m analyzer\u001b[39m.\u001b[39;49mdisplay_results()\n",
      "Cell \u001b[1;32mIn[33], line 48\u001b[0m, in \u001b[0;36mRiverAnalyzer.display_results\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m# Placeholder for coverage calculation\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConflation Results\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuantitative Coverage: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoverage_percentage,\u001b[39m \u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSection of River Covered: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: type NoneType doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "analyzer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-3764f5469f46>:33: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = self.river.geometry.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: upstream\n",
      "Conflation Results\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type NoneType doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m analyzer\u001b[39m.\u001b[39mfind_matching_instances()\n\u001b[0;32m      7\u001b[0m analyzer\u001b[39m.\u001b[39mclassify_river_part()\n\u001b[1;32m----> 8\u001b[0m analyzer\u001b[39m.\u001b[39;49mdisplay_results()\n",
      "Cell \u001b[1;32mIn[33], line 48\u001b[0m, in \u001b[0;36mRiverAnalyzer.display_results\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m# Placeholder for coverage calculation\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConflation Results\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuantitative Coverage: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoverage_percentage,\u001b[39m \u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSection of River Covered: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: type NoneType doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "analyzer = RiverAnalyzer(\n",
    "    json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "    parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "    gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    ")\n",
    "analyzer.find_matching_instances()\n",
    "analyzer.classify_river_part()\n",
    "analyzer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "class RiverAnalyzer:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_data = pd.read_json(json_path)\n",
    "        self.parq = gpd.read_parquet(parquet_path)\n",
    "        self.xs = gpd.read_file(gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(gpkg_path, layer=\"River\")\n",
    "        self.matching_instances = None\n",
    "        self.classification = None\n",
    "        self.coverage_percentage = 0  # Initialized to 0 or another appropriate default value\n",
    "\n",
    "    def find_matching_instances(self, river_id=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == river_id]\n",
    "\n",
    "    @staticmethod\n",
    "    def split_and_classify_line(line):\n",
    "        total_length = line.length\n",
    "        one_third_distance = total_length / 3\n",
    "        two_thirds_distance = 2 * total_length / 3\n",
    "\n",
    "        segments = [\n",
    "            LineString([line.interpolate(0), line.interpolate(one_third_distance)]),\n",
    "            LineString([line.interpolate(one_third_distance), line.interpolate(two_thirds_distance)]),\n",
    "            LineString([line.interpolate(two_thirds_distance), line.interpolate(total_length)])\n",
    "        ]\n",
    "\n",
    "        classifications = ['downstream', 'middle', 'upstream']\n",
    "        new_rows = [{'geometry': segment, 'classification': classification} for segment, classification in zip(segments, classifications)]\n",
    "\n",
    "        return gpd.GeoDataFrame(new_rows, columns=['geometry', 'classification'])\n",
    "\n",
    "    def classify_river_part(self):\n",
    "        centroid = self.matching_instances.geometry.centroid\n",
    "        river_line = self.river.geometry.unary_union\n",
    "        distance_from_start = river_line.project(centroid.iloc[0])\n",
    "        total_length_river = river_line.length\n",
    "\n",
    "        if distance_from_start < total_length_river / 3:\n",
    "            self.classification = \"downstream\"\n",
    "        elif distance_from_start < 2 * total_length_river / 3:\n",
    "            self.classification = \"middle\"\n",
    "        else:\n",
    "            self.classification = \"upstream\"\n",
    "\n",
    "    def calculate_coverage_percentage(self):\n",
    "        # Placeholder for actual coverage calculation logic\n",
    "        # This should be replaced with actual logic to calculate coverage percentage\n",
    "        self.coverage_percentage = 100.0  # Example value\n",
    "\n",
    "    def display_results(self):\n",
    "        # Ensure coverage_percentage has been calculated\n",
    "        if self.coverage_percentage is None:\n",
    "            self.calculate_coverage_percentage()  # Calculate if not already done\n",
    "\n",
    "        print(f\"The overlapping part of the river is classified as: {self.classification}\")\n",
    "        print(\"Conflation Results\")\n",
    "        print(f\"Quantitative Coverage: {round(self.coverage_percentage, 1)}%\")\n",
    "        print(f\"Section of River Covered: {self.classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: upstream\n",
      "Conflation Results\n",
      "Quantitative Coverage: 100.0%\n",
      "Section of River Covered: upstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-b0e30fbfac88>:37: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = self.river.geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "analyzer = RiverAnalyzer(\n",
    "    json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "    parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "    gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    ")\n",
    "analyzer.find_matching_instances()\n",
    "analyzer.classify_river_part()\n",
    "analyzer.calculate_coverage_percentage()  # Ensure this is called before display_results\n",
    "analyzer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflation Results\n",
      "Quantitative Coverage: 24.6%\n",
      "Segment: downstream, Length: 1115.3078920639875\n",
      "Segment: middle, Length: 873.916831508305\n",
      "Segment: upstream, Length: 643.6744431353446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "class RiverAnalyzer:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_path = json_path\n",
    "        self.parquet_path = parquet_path\n",
    "        self.gpkg_path = gpkg_path\n",
    "        self.json_data = None\n",
    "        self.parq = None\n",
    "        self.xs = None\n",
    "        self.river = None\n",
    "        self.matching_instances = None\n",
    "        self.read_data()\n",
    "    \n",
    "    def read_data(self):\n",
    "        self.json_data = pd.read_json(self.json_path)\n",
    "        self.parq = gpd.read_parquet(self.parquet_path)\n",
    "        self.xs = gpd.read_file(self.gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(self.gpkg_path, layer=\"River\")\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == 5998592]\n",
    "    \n",
    "    def calculate_coverage(self):\n",
    "        total_length_xs = self.xs.geometry.length.sum()\n",
    "        total_length_matching_instances = self.matching_instances.geometry.length.sum()\n",
    "        coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "        return coverage_percentage\n",
    "    \n",
    "    def split_and_classify_river(self):\n",
    "        river_line = unary_union(self.river.geometry)\n",
    "        total_length = river_line.length\n",
    "        one_third_distance = total_length / 3\n",
    "        two_thirds_distance = 2 * total_length / 3\n",
    "        segments = [\n",
    "            LineString([river_line.interpolate(0), river_line.interpolate(one_third_distance)]),\n",
    "            LineString([river_line.interpolate(one_third_distance), river_line.interpolate(two_thirds_distance)]),\n",
    "            LineString([river_line.interpolate(two_thirds_distance), river_line.interpolate(total_length)])\n",
    "        ]\n",
    "        classifications = ['downstream', 'middle', 'upstream']\n",
    "        return [(segment, classification) for segment, classification in zip(segments, classifications)]\n",
    "    \n",
    "    def display_results(self):\n",
    "        coverage_percentage = self.calculate_coverage()\n",
    "        split_river = self.split_and_classify_river()\n",
    "        print(\"Conflation Results\")\n",
    "        print(f\"Quantitative Coverage: {round(coverage_percentage, 1)}%\")\n",
    "        for segment, classification in split_river:\n",
    "            print(f\"Segment: {classification}, Length: {segment.length}\")\n",
    "\n",
    "# Example usage\n",
    "analyzer = RiverAnalyzer(\n",
    "    r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "    r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "    r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    ")\n",
    "analyzer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverAnalyzer:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_path = json_path\n",
    "        self.parquet_path = parquet_path\n",
    "        self.gpkg_path = gpkg_path\n",
    "        self.json_data = None\n",
    "        self.parq = None\n",
    "        self.xs = None\n",
    "        self.river = None\n",
    "        self.matching_instances = None\n",
    "        self.read_data()\n",
    "    \n",
    "    def read_data(self):\n",
    "        self.json_data = pd.read_json(self.json_path)\n",
    "        self.parq = gpd.read_parquet(self.parquet_path)\n",
    "        self.xs = gpd.read_file(self.gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(self.gpkg_path, layer=\"River\")\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == 5998592]\n",
    "    \n",
    "    def calculate_coverage(self):\n",
    "        total_length_xs = self.xs.geometry.length.sum()\n",
    "        total_length_matching_instances = self.matching_instances.geometry.length.sum()\n",
    "        coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "        return coverage_percentage\n",
    "    \n",
    "    def split_and_classify_river(self):\n",
    "        river_line = unary_union(self.river.geometry)\n",
    "        total_length = river_line.length\n",
    "        one_third_distance = total_length / 3\n",
    "        two_thirds_distance = 2 * total_length / 3\n",
    "        segments = [\n",
    "            LineString([river_line.interpolate(0), river_line.interpolate(one_third_distance)]),\n",
    "            LineString([river_line.interpolate(one_third_distance), river_line.interpolate(two_thirds_distance)]),\n",
    "            LineString([river_line.interpolate(two_thirds_distance), river_line.interpolate(total_length)])\n",
    "        ]\n",
    "        classifications = ['downstream', 'middle', 'upstream']\n",
    "        classified_segments = [(segment, classification) for segment, classification in zip(segments, classifications)]\n",
    "        \n",
    "        # Determine which segment the matching instances intersect with\n",
    "        intersecting_segment = None\n",
    "        for segment, classification in classified_segments:\n",
    "            if self.matching_instances.geometry.intersects(segment).any():\n",
    "                intersecting_segment = classification\n",
    "                break\n",
    "        \n",
    "        return classified_segments, intersecting_segment\n",
    "    \n",
    "    def display_results(self):\n",
    "        coverage_percentage = self.calculate_coverage()\n",
    "        split_river, intersecting_segment = self.split_and_classify_river()\n",
    "        print(\"Conflation Results\")\n",
    "        print(f\"Quantitative Coverage: {round(coverage_percentage, 1)}%\")\n",
    "        for segment, classification in split_river:\n",
    "            print(f\"Segment: {classification}, Length: {segment.length}\")\n",
    "        if intersecting_segment:\n",
    "            print(f\"The intersecting section of the river is: {intersecting_segment}\")\n",
    "        else:\n",
    "            print(\"No intersecting section found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflation Results\n",
      "Quantitative Coverage: 24.6%\n",
      "Segment: downstream, Length: 1115.3078920639875\n",
      "Segment: middle, Length: 873.916831508305\n",
      "Segment: upstream, Length: 643.6744431353446\n",
      "No intersecting section found.\n"
     ]
    }
   ],
   "source": [
    "analyzer = RiverAnalyzer(\n",
    "    r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "    r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "    r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    ")\n",
    "analyzer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mRiverAnalyzer\u001b[39;49;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, json_path, parquet_path, gpkg_path):\n\u001b[0;32m      3\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjson_path \u001b[39m=\u001b[39;49m json_path\n",
      "Cell \u001b[1;32mIn[44], line 41\u001b[0m, in \u001b[0;36mRiverAnalyzer\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m      \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoverage_percentage \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate_coverage_percentage()  \u001b[39m# Calculate if not already done\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe overlapping part of the river is classified as: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mclassification\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConflation Results\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuantitative Coverage: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoverage_percentage,\u001b[39m \u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "class RiverAnalyzer:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_path = json_path\n",
    "        self.parquet_path = parquet_path\n",
    "        self.gpkg_path = gpkg_path\n",
    "        self.json_data = None\n",
    "        self.parq = None\n",
    "        self.xs = None\n",
    "        self.river = None\n",
    "        self.matching_instances = None\n",
    "        self.read_data()\n",
    "    \n",
    "    def read_data(self):\n",
    "        self.json_data = pd.read_json(self.json_path)\n",
    "        self.parq = gpd.read_parquet(self.parquet_path)\n",
    "        self.xs = gpd.read_file(self.gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(self.gpkg_path, layer=\"River\")\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == 5998592]\n",
    "    \n",
    "    def calculate_coverage(self):\n",
    "        total_length_xs = self.xs.geometry.length.sum()\n",
    "        total_length_matching_instances = self.matching_instances.geometry.length.sum()\n",
    "        coverage_percentage = (total_length_matching_instances / total_length_xs) * 100\n",
    "        return coverage_percentage\n",
    "\n",
    "    def classify_river_part(self):\n",
    "    # Split the river into three sections and classify each\n",
    "        split_river_df = self.split_and_classify_line(self.river.geometry.unary_union)\n",
    "    \n",
    "    # Iterate through each section to find where the matching instances intersect\n",
    "        for index, row in split_river_df.iterrows():\n",
    "             if self.matching_instances.intersects(row['geometry']).any():\n",
    "                self.classification = row['classification']\n",
    "                break  # Stop once the intersecting section is found\n",
    "\n",
    "    def display_results(self):\n",
    "    # Ensure coverage_percentage has been calculated\n",
    "         if self.coverage_percentage is None:\n",
    "            self.calculate_coverage_percentage()  # Calculate if not already done\n",
    "\n",
    "    print(f\"The overlapping part of the river is classified as: {self.classification}\")\n",
    "    print(\"Conflation Results\")\n",
    "    print(f\"Quantitative Coverage: {round(self.coverage_percentage, 1)}%\")\n",
    "    print(f\"Section of River Covered: {self.classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverAnalyzer:\n",
    "    def __init__(self, json_path, parquet_path, gpkg_path):\n",
    "        self.json_data = pd.read_json(json_path)\n",
    "        self.parq = gpd.read_parquet(parquet_path)\n",
    "        self.xs = gpd.read_file(gpkg_path, layer=\"XS\")\n",
    "        self.river = gpd.read_file(gpkg_path, layer=\"River\")\n",
    "        self.matching_instances = None\n",
    "        self.classification = None\n",
    "        self.coverage_percentage = 0  # Initialized to 0 or another appropriate default value\n",
    "\n",
    "    def find_matching_instances(self, river_id=5998592):\n",
    "        self.matching_instances = self.parq[self.parq['ID'] == river_id]\n",
    "\n",
    "    @staticmethod\n",
    "    def split_and_classify_line(line):\n",
    "        total_length = line.length\n",
    "        one_third_distance = total_length / 3\n",
    "        two_thirds_distance = 2 * total_length / 3\n",
    "\n",
    "        segments = [\n",
    "            LineString([line.interpolate(0), line.interpolate(one_third_distance)]),\n",
    "            LineString([line.interpolate(one_third_distance), line.interpolate(two_thirds_distance)]),\n",
    "            LineString([line.interpolate(two_thirds_distance), line.interpolate(total_length)])\n",
    "        ]\n",
    "\n",
    "        classifications = ['downstream', 'middle', 'upstream']\n",
    "        new_rows = [{'geometry': segment, 'classification': classification} for segment, classification in zip(segments, classifications)]\n",
    "\n",
    "        return gpd.GeoDataFrame(new_rows, columns=['geometry', 'classification'])\n",
    "\n",
    "    def classify_river_part(self):\n",
    "        centroid = self.matching_instances.geometry.centroid\n",
    "        river_line = self.river.geometry.unary_union\n",
    "        distance_from_start = river_line.project(centroid.iloc[0])\n",
    "        total_length_river = river_line.length\n",
    "\n",
    "        if distance_from_start < total_length_river / 3:\n",
    "            self.classification = \"downstream\"\n",
    "        elif distance_from_start < 2 * total_length_river / 3:\n",
    "            self.classification = \"middle\"\n",
    "        else:\n",
    "            self.classification = \"upstream\"\n",
    "\n",
    "    def calculate_coverage_percentage(self):\n",
    "        # Placeholder for actual coverage calculation logic\n",
    "        # This should be replaced with actual logic to calculate coverage percentage\n",
    "        self.coverage_percentage = 100.0  # Example value\n",
    "\n",
    "    def display_results(self):\n",
    "        # Ensure coverage_percentage has been calculated\n",
    "        if self.coverage_percentage is None:\n",
    "            self.calculate_coverage_percentage()  # Calculate if not already done\n",
    "\n",
    "        print(f\"The overlapping part of the river is classified as: {self.classification}\")\n",
    "        print(\"Conflation Results\")\n",
    "        print(f\"Quantitative Coverage: {round(self.coverage_percentage, 1)}%\")\n",
    "        print(f\"Section of River Covered: {self.classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping part of the river is classified as: upstream\n",
      "Conflation Results\n",
      "Quantitative Coverage: 100.0%\n",
      "Section of River Covered: upstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-8565d106aebb>:33: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  river_line = self.river.geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "analyzer = RiverAnalyzer(\n",
    "    json_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4-nwm_conflation (1).json',\n",
    "    parquet_path=r'C:\\Users\\abiro\\Downloads\\nwm_flows_v3 (1).parquet',\n",
    "    gpkg_path=r'C:\\Users\\abiro\\Downloads\\BASIN FORK Trib 4.gpkg'\n",
    ")\n",
    "analyzer.find_matching_instances()\n",
    "analyzer.classify_river_part()\n",
    "analyzer.calculate_coverage_percentage()  # Ensure this is called before display_results\n",
    "analyzer.display_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
